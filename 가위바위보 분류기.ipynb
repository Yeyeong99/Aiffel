{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "198ed637",
   "metadata": {},
   "source": [
    "## 가위바위보 분류기 제작\n",
    "### 순서\n",
    "1. 이미지 크기 조절\n",
    "2. load_data() 함수 이용해 학습용 데이터 생성\n",
    "3. 딥러닝 네트워크 설계\n",
    "4. 딥러닝 네트워크 학습시키기\n",
    "5. 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61157868",
   "metadata": {},
   "source": [
    "### 1. 이미지 크기 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b8005a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# 이미지 크기 조절을 위해 PIL import\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "81b517b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 크기 조절을 위한 함수\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "55dd4c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500  images to be resized.\n",
      "500  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지 크기 조정\n",
    "image_dir_scissor = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_scissor)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bd65a021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500  images to be resized.\n",
      "500  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지 크기 조정\n",
    "image_dir_rock = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_rock)\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "33155907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500  images to be resized.\n",
      "500  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지 크기 조정\n",
    "image_dir_paper = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_paper)\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df7aebb",
   "metadata": {},
   "source": [
    "### 2. load_data() 함수 이용해 학습용 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0f89da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더 위치를 넘겨 받아 가위, 바위, 보를 각각 0, 1, 2로 라벨링 해주는 함수\n",
    "def load_data(img_path, number_of_data=1500):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"데이터의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c1ddf830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터의 이미지 개수는 1500 입니다.\n",
      "x_train shape: (1500, 28, 28, 3)\n",
      "y_train shape: (1500,)\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "90291a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지 확인\n",
    "plt.imshow(x_train_norm[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70083d6",
   "metadata": {},
   "source": [
    "### 3. 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e6304ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 35,875\n",
      "Trainable params: 35,875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "n_channel_1=32\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56475508",
   "metadata": {},
   "source": [
    "### 4. 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e56d8482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 1.0824 - accuracy: 0.3827\n",
      "Epoch 2/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 1.0070 - accuracy: 0.4440\n",
      "Epoch 3/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9427 - accuracy: 0.5033\n",
      "Epoch 4/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.8806 - accuracy: 0.5700\n",
      "Epoch 5/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.8040 - accuracy: 0.6440\n",
      "Epoch 6/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.7468 - accuracy: 0.6827\n",
      "Epoch 7/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.7407\n",
      "Epoch 8/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7820\n",
      "Epoch 9/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.8040\n",
      "Epoch 10/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.8187\n",
      "Epoch 11/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8593\n",
      "Epoch 12/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.8527\n",
      "Epoch 13/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3703 - accuracy: 0.8687\n",
      "Epoch 14/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3072 - accuracy: 0.8967\n",
      "Epoch 15/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2720 - accuracy: 0.9140\n",
      "Epoch 16/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2575 - accuracy: 0.9060\n",
      "Epoch 17/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2185 - accuracy: 0.9293\n",
      "Epoch 18/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9327\n",
      "Epoch 19/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1725 - accuracy: 0.9440\n",
      "Epoch 20/20\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1681 - accuracy: 0.9460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa0734718e0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1148b94",
   "metadata": {},
   "source": [
    "### 5. 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "216f8577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "데이터의 이미지 개수는 300 입니다.\n",
      "x_test shape: (1500, 28, 28, 3)\n",
      "y_test shape: (1500,)\n"
     ]
    }
   ],
   "source": [
    "# test 용 데이터 생성\n",
    "image_dir_s_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_s_test)\n",
    "\n",
    "image_dir_r_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_r_test)\n",
    "\n",
    "image_dir_p_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_p_test)\n",
    "\n",
    "image_dir_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_test)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test_norm.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e0d62dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 - 0s - loss: 1.1231 - accuracy: 0.8973\n",
      "test_loss: 1.1231224536895752 \n",
      "test_accuracy: 0.8973333239555359\n"
     ]
    }
   ],
   "source": [
    "# test accuracy 측정\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f8f39",
   "metadata": {},
   "source": [
    "### 결과 정리\n",
    "\n",
    "1. 처음 주어진 300개의 데이터로만 학습했을 때는 test accuracy가 대략 33%\n",
    "2. 네트워크 설계 단계에서 하이퍼파라미터를 변경해봤지만 성능이 크게 향상되지 않음\n",
    "3. 데이터의 수를 1500으로 늘리고 epoch를 10으로 설정한 후 시도 했을 때 대략 90퍼센트 내외의 정확도가 나옴.\n",
    "4. 데이터 수를 1500으로 고정한 뒤 학습을 시킬 때 epochs를 20으로 조정해 테스트를 시도하니 약 90퍼센트의 정확도까지 도달함."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
