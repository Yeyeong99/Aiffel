{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc5e219f",
   "metadata": {},
   "source": [
    "## 가위바위보 분류기 제작\n",
    "### 순서\n",
    "1. 이미지 크기 조절\n",
    "2. load_data() 함수 이용해 학습용 데이터 생성\n",
    "3. 딥러닝 네트워크 설계\n",
    "4. 딥러닝 네트워크 학습시키기\n",
    "5. 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e9154",
   "metadata": {},
   "source": [
    "### 1. 이미지 크기 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "76a0b57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# 이미지 크기 조절을 위해 PIL import\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a9d27a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 크기 조절을 위한 함수\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "33a133f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500  images to be resized.\n",
      "500  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지 크기 조정\n",
    "image_dir_scissor = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_scissor)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ff573e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500  images to be resized.\n",
      "500  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지 크기 조정\n",
    "image_dir_rock = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_rock)\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "1ecd435b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500  images to be resized.\n",
      "500  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지 크기 조정\n",
    "image_dir_paper = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_paper)\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf85623",
   "metadata": {},
   "source": [
    "### 2. load_data() 함수 이용해 학습용 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "7452851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더 위치를 넘겨 받아 가위, 바위, 보를 각각 0, 1, 2로 라벨링 해주는 함수\n",
    "def load_data(img_path, number_of_data=1500):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"데이터의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e4eda3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터의 이미지 개수는 1500 입니다.\n",
      "x_train shape: (1500, 28, 28, 3)\n",
      "y_train shape: (1500,)\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "65d506b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAATlElEQVR4nO3dX2xc9ZUH8O/XHo8dO06IAxsCDX8W8RIQhdZCRUUrVtVWlJfQF9Q8VFkJbfpQpFbqwyK62sIbWm1b9WFVKV1Q01WXUqlF5AHtNhsVZSNBFZP1Qghsk0KgCYndkE3ixPH/sw++rAz4njPMb+bOkN/3I1m25/je+/OdOZ7xnHt+P5oZROTK19PpAYhINZTsIplQsotkQskukgklu0gmalUerK9et4GBgaa3ZwvH8nEJVQn6I4vG3dPj/81dXFx047Xe3vJtl5bcbQcHB934dZs3u3EGv3t0bq5US8F59+7z6UvT7rbvnXqvfNvpy5ibm1v1pCclO8n7AfwIQC+AfzazJ72fHxgYwOgXRps+Xm9b092/c7wjRw/4KJmHhvyEO/+/59z4hg0bSmPT0/4D567PfdaN//13/86N12r+Q4i99fLYFfyH4uLUlBv3/sgeOnTI3faJJ54ojf3ngZdKY02/jCfZC+CfAHwFwFYA20lubXZ/ItJeKf+z3w3gmJm9ZWZzAH4BYFtrhiUirZaS7NcD+OOK708Ut30IyZ0kx0iOzc/PJRxORFK0/d14M9tlZqNmNtrXV/7/m4i0V0qynwSwZcX3nyluE5EulJLsBwHcSvJmknUAXwOwpzXDEpFWa7r0ZmYLJB8B8O9YLr09bWavpwwmLMW0sUEvOnZKESiqk8/N+e9lhGNz4lFXY19fX9Kxo9LewGD5NQApv1cjcU9qt2e0fXSfew4ePOjGp5yynnfcpDq7mb0A4IWUfYhINXS5rEgmlOwimVCyi2RCyS6SCSW7SCaU7CKZqLSfnUyrjfr7Tttv2G2ZsO/+/v6kY0dtpF7v9Pz8vLttNL9AXxCP6s21oI7fKe1uno3amicmJkpjL774orvt7Oxsacy7P/TMLpIJJbtIJpTsIplQsotkQskukgklu0gmKi29pUopr8XtksH2TR85Lk9F8TVr1rhxrzSX0moJAAjGFpX2avXE4zu6eVHS4XXr3Pj+/ftLY6dPn3a3HRkZKY31OtOK65ldJBNKdpFMKNlFMqFkF8mEkl0kE0p2kUwo2UUy8amqs3vSpyUO9p+w72i65b4+/25Y0++3mXrH9+quQFyrvnzpkhuPRK2euTpw4EBpbP369e621113XWmsXi9fAVb3hEgmlOwimVCyi2RCyS6SCSW7SCaU7CKZULKLZKKr6uzxssnl8XbX2XsSeukHBweDn0jrGZ+ZmSmNRXX2aJrq6LwNBX3bS4vl01yH90k31+iD6xP+61B5vRsADjnxqM7erKRkJ3kcwBSARQALZjbaikGJSOu14pn9L83sTAv2IyJt1MWvk0SklVKT3QD8huQrJHeu9gMkd5IcIzk2NzeXeDgRaVbqy/h7zewkyT8DsJfkm2b2oZn0zGwXgF0AsG79uu6dIVDkCpf0zG5mJ4vPkwCeA3B3KwYlIq3XdLKTHCI5/MHXAL4M4HCrBiYirZXyMn4TgOeKWmkNwL+a2b+1ZFQdkFqn90RLNpuV16IBYGHOr7N7c8NHdfQzZ/xCyssvv+zGvd5qAFh31cbSWOo1ANH23n0W9fF7y2A3En/22Wfd+Pnz50tj0e91+fLl0ph3TUbTyW5mbwH4bLPbi0i1VHoTyYSSXSQTSnaRTCjZRTKhZBfJROUtriklrPYet/mL+6J9nzt3zo0PDvpLMvfX6258YKB8qumFhQV32zfffNONv/v2cTceTRXd11/e3huVmPr6+pLiKaW3aKnrqPQ2Pj7uxr2256mpKXdb77Jzr/SmZ3aRTCjZRTKhZBfJhJJdJBNKdpFMKNlFMqFkF8lEpXV2M3PrvlHdNZzv2RHVTQG/bupNJR3VmoeGhtz4wkIwVfRi+VTRAFB36vDh9QXB5QXRNNZR+67XjhnVuiMp12xE1x9EU6hF24+MjLhx7/EY5YF3f3vb6pldJBNKdpFMKNlFMqFkF8mEkl0kE0p2kUwo2UUyUXk/u1dbjXqEraedSzb7f/dS6uxxjT+Nt/9obKnzC0R1eGP5Qyy1zh5t78VT75PovEX79+IpvfTe76xndpFMKNlFMqFkF8mEkl0kE0p2kUwo2UUyoWQXyUSldfalJcPs7GxpPOxn7y0fbmo9mfRrtr3O/qN6b9T73ONcPwAAhuZrutE57a35+14IlpOOasK1uj8nfoqUZZWjbSPR4y26z73HTMr1A57wmZ3k0yQnSR5ecdsIyb0kjxafNzR1dBGpTCMv438K4P6P3PYogH1mdiuAfcX3ItLFwmQ3s/0Azn7k5m0Adhdf7wbwYGuHJSKt1uz/7JvM7FTx9WkAm8p+kOROADsBoN7vr1kmIu2T/G68Lb9bUPqOgZntMrNRMxut1fyF+ESkfZpN9gmSmwGg+DzZuiGJSDs0m+x7AOwovt4B4PnWDEdE2iX8n53kMwDuA3A1yRMAvgfgSQC/JPkwgHcAPNTIwcyW3Dp7VLtcSqizR1Lq7Kn97LWaXwvvCersXs04XD+97h+bS/55ieZX75ktrzenXhuRssZ6ap29a/vZnfsrTHYz214S+lK0rYh0D10uK5IJJbtIJpTsIplQsotkQskukonKp5JOKXkson2llGjJ5kWn1JJaIrKgjbQ3mOa62amFAWBh0R97T9BNGe3/0uWp8n0HpbfUcmpKi2s4rXliG2pK6c2dInvJmVbc3auIXDGU7CKZULKLZELJLpIJJbtIJpTsIplQsotkotI6O0n09ZXPVhO2Y/YEU00nMPNrm96SzanLHkebp9SjoymNoxbVutNWDAADAwNunL3NT5kc1bqj8+5No506/XdKGyrgjz3l8USnHVrP7CKZULKLZELJLpIJJbtIJpTsIplQsotkQskukomuqrNHywvXnL7u1N7nqJ/dq7On9mUvLvo13b6g1u2d0+npaXfbhWm/zu7tGwCuuuoqN76E8vvUm1a8kXhUy/YeT+G05cG+ozp8Sp0+Zbln7/fSM7tIJpTsIplQsotkQskukgklu0gmlOwimVCyi2Si8nnj3TpgUPvsdfrZU5f/beeSzfV63Y3Pzfn15HrNr3X39/eXxqJ68eWZS248qrMPDw+78YWl8vMe9ZRHvfbR9t59Xqv5D/2UfTfCe8ykrEPgbRs+s5N8muQkycMrbnuc5EmS48XHA9F+RKSzGnkZ/1MA969y+w/N7M7i44XWDktEWi1MdjPbD+BsBWMRkTZKeYPuEZKvFi/zN5T9EMmdJMdIjs3PzyccTkRSNJvsPwZwC4A7AZwC8P2yHzSzXWY2amaj0Zs9ItI+TSW7mU2Y2aItLz/6EwB3t3ZYItJqTSU7yc0rvv0qgMNlPysi3SGss5N8BsB9AK4meQLA9wDcR/JOAAbgOIBvNHKwHhIDtfJaedTPntKfHNUue3r8eM2p8UfjNmddeQDYMLzWjc/MzLjxwYHyOv7QmtK3UwAAf/j9ETd+7daNbnyg3//XbGhgqDQ2c+Gcu+3pd4+78Y3XXOPGb7r5xvJjB+f04sWLbry+1r++INq/17MeXV8w76zB7kz5ECe7mW1f5eanou1EpLvoclmRTCjZRTKhZBfJhJJdJBNKdpFMVN7i6pWpurn05rXXRuNeCtolo2WPo3ZM78rEixcvuNtGLbDRVY/r1q1z4yffPVkaO3r0qLvtpk2b3Phdn/+8G/fKX9EU29EU2RcuTrnxlKtFo/ZaLDXXHqtndpFMKNlFMqFkF8mEkl0kE0p2kUwo2UUyoWQXyUTlSzZ7NeNurrOntLi6fYcNbB+N3Tun3tLAjRz78uXLbvzsWX96wpdeeqk0tmXLFnfbKB61kXqPiY0b/dbdaN9r1qxx49H1CylTqvd4La7esubuXkXkiqFkF8mEkl0kE0p2kUwo2UUyoWQXyYSSXSQTldfZU2rln9Z+9p4g7k0rDKQtHxxt6y33DACTk5NufGJiwo3fcMMNpbHbbrvN3fbaa69142eCGr93jUG0jHZUJ0/dPnq8+jv3avTqZxfJnpJdJBNKdpFMKNlFMqFkF8mEkl0kE0p2kUxUPm+8O691Qq08rqMHPcJBnd3bPrWGz2Ca8GjeeO/4ly5dcreN6vAXLvjzzkf97jfcVV5nP3DggLvtPffc48ZvvPlmN/7222+XxmZnZ91th4bKl5oGgPlF/9qIlF77cB0C/+FUfszoB0huIflbkkdIvk7yW8XtIyT3kjxafPYXAheRjmrkZfwCgO+Y2VYAXwDwTZJbATwKYJ+Z3QpgX/G9iHSpMNnN7JSZHSq+ngLwBoDrAWwDsLv4sd0AHmzTGEWkBT7RG3QkbwJwF4DfAdhkZqeK0GkAqy7MRXInyTGSY3NzcyljFZEEDSc7ybUAfgXg22b2oXdtbPldnlXf6TGzXWY2amajUfOAiLRPQ8lOsg/Lif5zM/t1cfMEyc1FfDMAvz1KRDoqLL1xua7zFIA3zOwHK0J7AOwA8GTx+flGDphWwmp++t1o3ynx+NhuGPVged9o2mLv36OoRTUqQUWvxqKljcfHx0tjZ86ccbe95ZZb3Pj6DX4ByFsKO/q9ovMSlSzjUm/zeeDHy2ON1Nm/CODrAF4jOV7c9hiWk/yXJB8G8A6AhxrYl4h0SJjsZnYA5X8uvtTa4YhIu+hyWZFMKNlFMqFkF8mEkl0kE0p2kUxUPpV0SmtfO+vsKS2ucU3VDYc122haYq8mfO7cOXfbWsIy2UA8FfVMrbzVc+vWre623jTUgH99AeCPbe3ate6277//vhtfNP8+ic5LSru2v235dnpmF8mEkl0kE0p2kUwo2UUyoWQXyYSSXSQTSnaRTFQ+lXS7+ng7OZV0vNS0v++5Gb932lt6GPCnc462HQx65aMa/9TUlBv36tnHjh1zt7399tvd+Obrr3fjx48fL41tCHrhoz79mbm0+8yTOvdCGT2zi2RCyS6SCSW7SCaU7CKZULKLZELJLpIJJbtIJiqvs0e9256UOns7Rb9T9Ct785sDwPT0tBs/ceJEaSyaHz0ae9SXHfWUe8ePlmSORL36GzduLI1Fv/f8/Lwbj64/OHLkiBv3ro2Ilos+ceq90pi3RLee2UUyoWQXyYSSXSQTSnaRTCjZRTKhZBfJhJJdJBONrM++BcDPAGwCYAB2mdmPSD4O4G8A/Kn40cfM7IV2DfTTLKpVL875Nd2onuz1lKdefxCtUx7NK3/HHXeUxqJ15/uCdevng55xr1Ye1cmj+MKSf+xw7M7Y0tZASFuffQHAd8zsEMlhAK+Q3FvEfmhm/9jAPkSkwxpZn/0UgFPF11Mk3wDgTxEiIl3nE/3PTvImAHcB+F1x0yMkXyX5NMlV5/khuZPkGMmx2Vn/0koRaZ+Gk53kWgC/AvBtM7sA4McAbgFwJ5af+b+/2nZmtsvMRs1stL/fv05bRNqnoWQn2YflRP+5mf0aAMxswswWzWwJwE8A3N2+YYpIqjDZufzW31MA3jCzH6y4ffOKH/sqgMOtH56ItEoj78Z/EcDXAbxGcry47TEA20neieVy3HEA32jD+K4IUSlldmHBjU9OTrrxs2fPlsaGh/12yagwF5XeoimXh4eHS2PReYmmY14Izpu3ffLU4/BbZKOxp5TevPZYr2TYyLvxB7D6Y0I1dZFPEV1BJ5IJJbtIJpTsIplQsotkQskukgklu0gmKp9KOkdRrTqKnz9/3o17U01fffWIu+18MBV01OoZLX3sjT1qj43qzQjiXptpreY/9KM6+dJ82lTU0RTcHq/OvnxB6+r0zC6SCSW7SCaU7CKZULKLZELJLpIJJbtIJpTsIplgyhLKn/hg5J8AvLPipqsBnKlsAJ9Mt46tW8cFaGzNauXYbjSza1YLVJrsHzs4OWZmox0bgKNbx9at4wI0tmZVNTa9jBfJhJJdJBOdTvZdHT6+p1vH1q3jAjS2ZlUyto7+zy4i1en0M7uIVETJLpKJjiQ7yftJ/g/JYyQf7cQYypA8TvI1kuMkxzo8lqdJTpI8vOK2EZJ7SR4tPvsN5dWO7XGSJ4tzN07ygQ6NbQvJ35I8QvJ1kt8qbu/ouXPGVcl5q/x/dpK9AH4P4K8AnABwEMB2MztS6UBKkDwOYNTMOn4BBsm/AHARwM/M7Pbitn8AcNbMniz+UG4ws7/tkrE9DuBip5fxLlYr2rxymXEADwL4a3Tw3DnjeggVnLdOPLPfDeCYmb1lZnMAfgFgWwfG0fXMbD+Ajy73sg3A7uLr3Vh+sFSuZGxdwcxOmdmh4uspAB8sM97Rc+eMqxKdSPbrAfxxxfcn0F3rvRuA35B8heTOTg9mFZvM7FTx9WkAmzo5mFWEy3hX6SPLjHfNuWtm+fNUeoPu4+41s88B+AqAbxYvV7uSLf8P1k2104aW8a7KKsuM/79Onrtmlz9P1YlkPwlgy4rvP1Pc1hXM7GTxeRLAc+i+pagnPlhBt/jsr/pYoW5axnu1ZcbRBeeuk8ufdyLZDwK4leTNJOsAvgZgTwfG8TEkh4o3TkByCMCX0X1LUe8BsKP4egeA5zs4lg/plmW8y5YZR4fPXceXPzezyj8APIDld+T/AOC7nRhDybj+HMB/Fx+vd3psAJ7B8su6eSy/t/EwgI0A9gE4CuA/AIx00dj+BcBrAF7FcmJt7tDY7sXyS/RXAYwXHw90+tw546rkvOlyWZFM6A06kUwo2UUyoWQXyYSSXSQTSnaRTCjZRTKhZBfJxP8Bn8XDiSnVPqgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지 확인\n",
    "plt.imshow(x_train_norm[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3583a9f6",
   "metadata": {},
   "source": [
    "### 3. 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ebf28120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 35,875\n",
      "Trainable params: 35,875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "n_channel_1=32\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb26f653",
   "metadata": {},
   "source": [
    "### 4. 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3871313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 1.0820 - accuracy: 0.3993\n",
      "Epoch 2/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9879 - accuracy: 0.4773\n",
      "Epoch 3/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.8592 - accuracy: 0.5827\n",
      "Epoch 4/15\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7235 - accuracy: 0.7013\n",
      "Epoch 5/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.7427\n",
      "Epoch 6/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.8280\n",
      "Epoch 7/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.8167\n",
      "Epoch 8/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.8627\n",
      "Epoch 9/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3534 - accuracy: 0.8880\n",
      "Epoch 10/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.9073\n",
      "Epoch 11/15\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.9227\n",
      "Epoch 12/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2263 - accuracy: 0.9207\n",
      "Epoch 13/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1867 - accuracy: 0.9407\n",
      "Epoch 14/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1644 - accuracy: 0.9507\n",
      "Epoch 15/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.9520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff243d52460>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eacf51",
   "metadata": {},
   "source": [
    "### 5. 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "9ea34e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "데이터의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# test 용 데이터 생성\n",
    "image_dir_s_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_s_test)\n",
    "\n",
    "image_dir_r_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_r_test)\n",
    "\n",
    "image_dir_p_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_p_test)\n",
    "\n",
    "image_dir_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_test, 300)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test_norm.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "6daf68d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 2.6312 - accuracy: 0.6233\n",
      "test_loss: 2.6311638355255127 \n",
      "test_accuracy: 0.6233333349227905\n"
     ]
    }
   ],
   "source": [
    "# test accuracy 측정\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228b0beb",
   "metadata": {},
   "source": [
    "### 결과 정리\n",
    "\n",
    "1. 처음 주어진 300개의 데이터로만 학습했을 때는 test accuracy가 대략 33%\n",
    "2. 네트워크 설계 단계에서 하이퍼파라미터를 변경해봤지만 성능이 크게 향상되지 않음\n",
    "3. 데이터의 수를 1500으로 늘리고 epoch를 10으로 설정한 후 시도 했을 때 대략 90퍼센트 내외의 정확도가 나옴.\n",
    "4. 데이터 수를 1500으로 고정한 뒤 학습을 시킬 때 epochs를 15으로 조정해 테스트를 시도하니 약 62퍼센트의 정확도까지 도달함."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
